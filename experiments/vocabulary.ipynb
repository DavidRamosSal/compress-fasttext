{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path = 'C:/Users/ddale/Downloads/NLP/rusvectores/model.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_ft = gensim.models.fasttext.FastTextKeyedVectors.load(original_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_words = big_ft.vocab.keys()\n",
    "with open('../data/model_vocab/model_vocab.txt', 'w', encoding='utf-8') as f:\n",
    "    for w in sorted(vocab_words):\n",
    "        f.write(w+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# taiga social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = 'C:/Users/ddale/Downloads/NLP/taiga/home/tsha/social/texts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbtexts.txt\n",
      "LiveJournalPostsandcommentsGICR.txt\n",
      "twtexts.txt\n",
      "vktexts.txt\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "raw_counter = Counter()\n",
    "\n",
    "for fn in os.listdir(text_path):\n",
    "    if not fn.endswith('txt'):\n",
    "        continue\n",
    "    print(fn)\n",
    "    with open(os.path.join(text_path, fn), 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            for w in re.sub('[^а-яёa-z]', ' ', line.lower()).split():\n",
    "                if w:\n",
    "                    raw_counter[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037674\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 1795982),\n",
       " ('в', 1710324),\n",
       " ('не', 1233161),\n",
       " ('на', 896576),\n",
       " ('databaseitem', 782967),\n",
       " ('что', 730842),\n",
       " ('а', 645086),\n",
       " ('o', 598672),\n",
       " ('с', 576451),\n",
       " ('d', 495602),\n",
       " ('это', 463749),\n",
       " ('я', 456344),\n",
       " ('dc', 419553),\n",
       " ('dd', 418957),\n",
       " ('как', 410708),\n",
       " ('a', 410427),\n",
       " ('то', 406144),\n",
       " ('c', 398109),\n",
       " ('quot', 395213),\n",
       " ('b', 374821)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "morphAnalyzer = MorphAnalyzer()\n",
    "\n",
    "def w2lemma(w):\n",
    "    parsed = morphAnalyzer.parse(w)\n",
    "    if not parsed:\n",
    "        return w\n",
    "    nf = parsed[0].normal_form.replace('ё', 'е')\n",
    "    return nf or w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b9b65a10ba41b29df809ad036e9869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1037674.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lemma_counter = Counter()\n",
    "for w, c in tqdm(raw_counter.items()):\n",
    "    lemma_counter[w2lemma(w)] += c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561921\n"
     ]
    }
   ],
   "source": [
    "print(len(lemma_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/model_vocab/taiga_social_vocab_raw.pkl', 'wb') as f:\n",
    "    pickle.dump(raw_counter, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/model_vocab/taiga_social_vocab_lemma.pkl', 'wb') as f:\n",
    "    pickle.dump(lemma_counter, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vocab = set()\n",
    "with open('../data/model_vocab/model_vocab.txt', 'r', encoding='utf-8') as f:\n",
    "    for l in f.readlines():\n",
    "        model_vocab.add(l.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_letters = set('абвгдеёжзиклмнопрстуфхцчшщъыьэюя')\n",
    "\n",
    "def is_ru_word(w):\n",
    "    if not set(w).intersection(russian_letters):\n",
    "        return False\n",
    "    if len(w) < 2:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_lemmas = Counter({w: c for w, c in lemma_counter.items() if w not in model_vocab and is_ru_word(w)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_lemmas = Counter({w: c for w, c in lemma_counter.items() if w in model_vocab and is_ru_word(w)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lemmas = Counter({w: c for w, c in lemma_counter.items() if is_ru_word(w)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361238"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oov_lemmas),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26186\n"
     ]
    }
   ],
   "source": [
    "top_oov_lemmas = [w for w, c in oov_lemmas.most_common() if c >= 10]\n",
    "print(len(top_oov_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79930\n"
     ]
    }
   ],
   "source": [
    "top_all_lemmas = [w for w, c in all_lemmas.most_common() if c >= 10]\n",
    "print(len(top_all_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53744\n"
     ]
    }
   ],
   "source": [
    "top_inv_lemmas = [w for w, c in inv_lemmas.most_common() if c >= 10]\n",
    "print(len(top_inv_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['разо',\n",
       " 'вконтактик',\n",
       " 'эмергенция',\n",
       " 'ковалек',\n",
       " 'мелиссандра',\n",
       " 'йный',\n",
       " 'гюрза',\n",
       " 'авалон',\n",
       " 'путний',\n",
       " 'асеана']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(top_oov_lemmas, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/model_vocab/taiga_social_in_vocab.txt', 'w', encoding='utf-8') as f:\n",
    "    for w in top_inv_lemmas:\n",
    "        f.write(w+'\\n')\n",
    "\n",
    "with open('../data/model_vocab/taiga_social_out_of_vocab.txt', 'w', encoding='utf-8') as f:\n",
    "    for w in top_oov_lemmas:\n",
    "        f.write(w+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
